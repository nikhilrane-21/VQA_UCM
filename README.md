# VQA_with_UCM_Dataset

# Dataset

## RSIVQA (Remote Sensing Image Visual Question Answering)
RSIVQA is a remote sensing visual question answering dataset proposed in the paper "Mutual Attention Inception Network for Remote Sensing Visual Question Answering".
If this data set is used in your work, please cite our paper.

[1] X. Zheng, B. Wang, X. Du, and X. Lu, “Mutual Attention Inception Network for Remote Sensing Visual Question Answering,” IEEE Transactions on Geoscience Remote Sensing, 2021.a

@article{
9444570,
author = {Zheng, Xiangtao and Wang, Binqiang and Du, Xingqian and Lu, Xiaoqiang},
doi = {10.1109/TGRS.2021.3079918},
issn = {0196-2892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
title = {{Mutual Attention Inception Network for Remote Sensing Visual Question Answering}},
year = {2021}
}

## Overview

RSIVQA dataset is derived from existing *remote sensing image* (RSI) datasets with a specially designed generation method.   

UCM Images Dataset Link
[UCM](http://weegee.vision.ucmerced.edu/datasets/landuse.html)

Questions and answers are generated based on images to form image-question-answer triplets. Questions, answers and their correspondence can 
be found in txt files in this repository.

# Model

# Train
